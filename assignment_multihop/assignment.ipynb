{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment â€” Multi-hop Reasoning on Knowledge graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Knowledge graph embedding allows predicting missed links in the graph. However, it does not allow to answer to complex logical queries.\n",
    "\n",
    "For example, one can want to answer `Where did Canadian citizens with Turing Award graduate?` Such question can be decomposed into several smaller questions and construct DAG (directed acyclic graph) of logical operations.\n",
    "\n",
    "\n",
    "<img src='https://github.com/netspractice/network-science/raw/main/assignment_multihop/model.png' width=700>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torchkge -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchkge import KnowledgeGraph\n",
    "from torchkge.utils import Trainer\n",
    "from torchkge.models.bilinear import RESCALModel\n",
    "from torchkge.utils import MarginLoss\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from zlib import adler32\n",
    "from tqdm.notebook import trange"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1. Beam search with RESCAL (3 point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beam-search is a technique of generating most probable sequences.\n",
    "\n",
    "<img src='https://github.com/netspractice/network-science/raw/main/assignment_multihop/beamsearch.png' width=600>\n",
    "\n",
    "It works as follows:\n",
    "1. Start from some root (`<START>` token on image)\n",
    "2. Predict subsequent tokens\n",
    "3. Select `k` most probable subsequences from generated\n",
    "4. Repeat the procedure\n",
    "\n",
    "In the current task, we will apply it to the query represented in the sequential form. We will work with the queries that can be represented in conjunctive normal form. For example, we have a query `What country was replaced by Canada neighbours`. `Canada neighbors` can be found by prediction tail `t` for query `h = \"Canada\"`, `r = \"shares border with\"`. And `What country was replaced by` could be represented as a tail for query `h = t`, `r = \"replaces\"`. So our query can be decomposed into two smaller ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/netspractice/network-science/main/datasets/countries_edges.tsv'\n",
    "open('countries_edges.tsv', 'wb').write(requests.get(url).content)\n",
    "url = 'https://raw.githubusercontent.com/netspractice/network-science/main/datasets/countries_entities.tsv'\n",
    "open('countries_entities.tsv', 'wb').write(requests.get(url).content)\n",
    "url = 'https://raw.githubusercontent.com/netspractice/network-science/main/datasets/countries_relations.tsv'\n",
    "open('countries_relations.tsv', 'wb').write(requests.get(url).content);\n",
    "\n",
    "edges = pd.read_csv('countries_edges.tsv', sep='\t').values\n",
    "entity_labels = pd.read_csv('countries_entities.tsv', sep='\t', index_col=0).label.values\n",
    "relation_labels = pd.read_csv('countries_relations.tsv', sep='\t', index_col=0).label.values\n",
    "\n",
    "edges_labeled = np.stack([entity_labels[edges[:, 0]], \n",
    "                          entity_labels[edges[:, 1]], \n",
    "                          relation_labels[edges[:, 2]]], axis=1)\n",
    "\n",
    "df = pd.DataFrame(edges_labeled, columns=['h', 't', 'r'])[['h', 'r', 't']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, we need to check if the answer is in the given dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbors = set(df[(df.h == 'Canada') & (df.r == \"shares border with\")].t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a6d27fbcbde0a861fa2805e83307bfc7",
     "grade": false,
     "grade_id": "cell-3c9f642cb829f305",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def find_replaces(df, neighbors):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4c3c45da08045deae06957a84e43b6ff",
     "grade": true,
     "grade_id": "cell-25635e4d2ac7c6c5",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "el = find_replaces(df, neighbors).pop()\n",
    "assert adler32(el.encode()) == 2730560188\n",
    "print(el)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can find an answer in our dataset, but for complex queries or incomplete graphs, such a task could be very hard. So we can work with knowledge graph embedding models to solve it. Firstly, let us initialize the knowledge graph dataset from torchkge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kg = KnowledgeGraph(pd.DataFrame(edges_labeled, columns=['from', 'to', 'rel']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Secondly, we need to train the fine embedding model. We will use `RESCALModel` from torchkge. Similarly to the TransE model from the previous seminar, it learns two embedding tensors. However, instead of embed relations, it learns the projection matrix for each relation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RESCALModel(emb_dim=128, n_entities=kg.n_ent, n_relations=kg.n_rel)\n",
    "criterion = MarginLoss(margin=0.5)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model, criterion, kg, n_epochs=50, \n",
    "    batch_size=512, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the model trained, we need to find the top $k$ most similar tails to our head and relation.\n",
    "\n",
    "You need to define the `find_most_similar` function that takes our trained model, knowledge graph, head and relation from a query in string form and the number of most similar items to return.\n",
    "\n",
    "It works as follows:\n",
    "1. Extract embeddings from the model using `get_embeddings` method\n",
    "2. Extract vectors for head\n",
    "3. Extract matrix for relation\n",
    "4. Calculate predicted embedding for via matrix multiplication over head vector and relation matrix\n",
    "5. Normalize predicted vector\n",
    "6. Calculate cosine similarity between predicted embedding and each entity from entity embedding matrix (dot product)\n",
    "\n",
    "Return np.array with indices of the top k most similar entities and np.array with corresponding similarities sorted in descending order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8c16f73b5bc303a2d3ce80324d4245f2",
     "grade": false,
     "grade_id": "cell-e4e87013d896c76c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def find_most_similar(model, kg, head, relation, k):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fb3401d735d2cb83c50626a1c18c0449",
     "grade": true,
     "grade_id": "cell-8254be5ac8f94775",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "ids, sims = find_most_similar(model, kg, \"Canada\", \"shares border with\", 5)\n",
    "assert len(ids) == 5\n",
    "assert ((sims[:-1] - sims[1:]) >= 0).mean() == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can try to answer to our query in two steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3245940fd3f81083a873d62f9ea66d1f",
     "grade": true,
     "grade_id": "cell-bc16ae4353cb8eef",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# 1\n",
    "ids, sims = find_most_similar(model, kg, \"Canada\", \"shares border with\", 5)\n",
    "\n",
    "# 2\n",
    "ix2ent = list(kg.ent2ix.keys())\n",
    "results = []\n",
    "for i in ids:\n",
    "    idx, s = find_most_similar(model, kg, ix2ent[i], \"replaces\", 5)\n",
    "    score_matrix = np.outer(sims, s).flatten()\n",
    "    topk = score_matrix.argsort()[-5:]\n",
    "    results.extend(zip(idx[topk % 5], score_matrix[topk]))\n",
    "results_topk = sorted(results, key=lambda x: x[1])[-5:]\n",
    "results_topk_entities = [ix2ent[j] for j, _ in results_topk]\n",
    "\n",
    "assert 2730560188 in [adler32(i.encode()) for i in results_topk_entities]\n",
    "print('\\n'.join(results_topk_entities))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2. Query2Box (7 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source http://snap.stanford.edu/query2box/\n",
    "\n",
    "Query2Box additionally allow to model union (disjunction) queries.\n",
    "\n",
    "\n",
    "The general idea behind Query2Box is to model sets as boxes. If an entity is in the set, then the corresponding embedding should lie inside the query box. The box is defined by the vector of centre and offset.\n",
    "\n",
    "The projection (existential operator) works similarly to the translation models: the model sums the centres and offsets.\n",
    "The intersection of the boxes could be found by performing attention over box queries. Offsets are calculated using DeepSets over the boxes and are shrunk with the sigmoid function.\n",
    "\n",
    "A simple geometric union of the boxes could be a bad idea because query boxes could lie in different places of our space. So, before doing union, the authors propose transforming our query to the disjunctive normal form (DNF).\n",
    "It allows to perform all box logic with projection and intersection operators and, finally, found the best entities close to one of the resulting boxes.\n",
    "\n",
    "<img src='http://snap.stanford.edu/query2box/dnf.png' width=700>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us download the realized models from https://github.com/snap-stanford/KGReasoning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/snap-stanford/KGReasoning/main/models.py'\n",
    "with open(\"models.py\", \"wb\") as f:\n",
    "    f.write(requests.get(url).content)\n",
    "    \n",
    "url = 'https://raw.githubusercontent.com/snap-stanford/KGReasoning/main/dataloader.py'\n",
    "with open(\"dataloader.py\", \"wb\") as f:\n",
    "    f.write(requests.get(url).content)\n",
    "    \n",
    "url = 'https://raw.githubusercontent.com/snap-stanford/KGReasoning/main/util.py'\n",
    "with open(\"util.py\", \"wb\") as f:\n",
    "    f.write(requests.get(url).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, we define types of queries we will prefer to handle.\n",
    "\n",
    "* 1p is one-projection query\n",
    "* 2p is two-projection query\n",
    "* 2i is two-intersection query\n",
    "* 2u-DNF is a disjunctive normal form, i.e. union (disjunction) between two 1p queries (Q2B)\n",
    "\n",
    "Naming convention: p projection, i intersection, n negation, u union."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_name_dict = {\n",
    "    ('e',('r',)): '1p', \n",
    "    ('e', ('r', 'r')): '2p',\n",
    "    (('e', ('r',)), ('e', ('r',))): '2i',\n",
    "    (('e', ('r',)), ('e', ('r',)), ('u',)): '2u-DNF',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is e â€”Â entity, r â€”Â relation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to generate the disjunctive examples for training.\n",
    "\n",
    "We will generate union pairs only for relation type `shares border with`.\n",
    "`generate_queries_disjunction` takes the data frame with triplets, entity to index converter, relation to index converter, number of elements in subsample and random_state for sampling.\n",
    "\n",
    "1. Generate one-hop queries\n",
    "2. Generate two samples from step 1 using `df.sample(n, random_state=random_state)`\n",
    "3. zip one-hop queries and construct union query (e.g. `((187, (41, )), (1071, (41, )), (-1,))`)\n",
    "4. construct answers as unions of answers for one-hop queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "44bc343a09394d8ba5d088e4163e8910",
     "grade": false,
     "grade_id": "cell-847174c7a86df6ac",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def generate_queries_disjunction(df, ent2id, rel2id, n, random_state=0):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example how the query and answer look like\n",
    "```python\n",
    "query, answer = generate_queries_disjunction(df, kg.ent2ix, kg.rel2ix, 1, 0)\n",
    "assert query == [(((36, (41,)), (616, (41,)), (-1,)), (('e', ('r',)), ('e', ('r',)), ('u',)))]\n",
    "assert answer == {((36, (41,)), (616, (41,)), (-1,)): {1026, 611, 1157, 1574, 710, 1256, 1257, 1676, 1560, 669, 216}}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_queries_dis = []\n",
    "train_answers_dis = {}\n",
    "for i in trange(500):\n",
    "    tq, ta = generate_queries_disjunction(df, kg.ent2ix, kg.rel2ix, 300, random_state=2 * i)\n",
    "    train_queries_dis.extend(tq)\n",
    "    train_answers_dis.update(ta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c755cf47959734702104a04674d02920",
     "grade": true,
     "grade_id": "cell-f56796364508c056",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert train_queries_dis[0][1] == (('e', ('r',)), ('e', ('r',)), ('u',))\n",
    "assert (((129, (41,)), (1706, (41,)), (-1,)), (('e', ('r',)), ('e', ('r',)), ('u',))) in train_queries_dis\n",
    "assert sum(train_answers_dis[(((129, (41,)), (1706, (41,)), (-1,)))]) == 2267"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize model, optimizer and train iterator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q2b_model = models.KGReasoning(\n",
    "    nentity=kg.n_ent,\n",
    "    nrelation=kg.n_rel,\n",
    "    hidden_dim=800,\n",
    "    gamma=24,\n",
    "    geo=\"box\",\n",
    "    use_cuda=False,\n",
    "    box_mode=('relu', 0.05),\n",
    "    beta_mode=None,\n",
    "    test_batch_size=128,\n",
    "    query_name_dict=query_name_dict\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    filter(lambda p: p.requires_grad, q2b_model.parameters()), \n",
    "    lr=0.01\n",
    ")\n",
    "\n",
    "train_path_iterator = SingledirectionalOneShotIterator(DataLoader(\n",
    "    TrainDataset(train_queries_dis, kg.n_ent, kg.n_rel, 128, train_answers_dis),\n",
    "    batch_size=512,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    collate_fn=TrainDataset.collate_fn\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will try to answer the question `What countries share a border with Canada or Mexico?`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(df[(df.h == 'Mexico') & (df.r == 'shares border with')].\\\n",
    "    append(df[(df.h == 'Canada') & (df.r == 'shares border with')]).t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in trange(50):\n",
    "    q2b_model.train_step(q2b_model, optimizer, train_path_iterator, args,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ad575febb54adb3f0739de4f4f7dfc1a",
     "grade": true,
     "grade_id": "cell-f721f2b1aac81494",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "ans = predict_kg_reasoning(\n",
    "    q2b_model,\n",
    "    kg,\n",
    "    [kg.ent2ix['Canada'], kg.rel2ix['shares border with'], kg.ent2ix['Mexico'], kg.rel2ix['shares border with'], -1],\n",
    "    (('e', ('r',)), ('e', ('r',)), ('u',)), k=10, ix2ent=ix2ent)\n",
    "hashed = [adler32(i.encode()) for i in ans]\n",
    "assert 1847527621 in hashed\n",
    "assert 1897990456 in hashed\n",
    "assert 131007068 in hashed\n",
    "assert 295175058 in hashed\n",
    "assert 292684689 in hashed\n",
    "print('\\n'.join(ans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
